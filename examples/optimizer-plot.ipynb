{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# ML Toolkit\n",
    "from robusta.optimizer import GridSearchCV, RandomSearchCV, OptunaCV\n",
    "from robusta.crossval import crossval_predict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Model\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=666)\n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "\n",
    "X.rename(columns=lambda x: 'x{}'.format(x), inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>-3.135568</td>\n",
       "      <td>-0.682559</td>\n",
       "      <td>-0.740026</td>\n",
       "      <td>-1.565277</td>\n",
       "      <td>0.653032</td>\n",
       "      <td>-0.910702</td>\n",
       "      <td>-1.571373</td>\n",
       "      <td>-0.106283</td>\n",
       "      <td>-0.794989</td>\n",
       "      <td>0.250017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>535</td>\n",
       "      <td>-0.220983</td>\n",
       "      <td>1.681607</td>\n",
       "      <td>1.541841</td>\n",
       "      <td>-0.190491</td>\n",
       "      <td>1.520588</td>\n",
       "      <td>0.938335</td>\n",
       "      <td>1.503033</td>\n",
       "      <td>-0.538354</td>\n",
       "      <td>0.116053</td>\n",
       "      <td>0.690656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>695</td>\n",
       "      <td>-0.106349</td>\n",
       "      <td>-0.442650</td>\n",
       "      <td>1.933125</td>\n",
       "      <td>-0.034856</td>\n",
       "      <td>0.534739</td>\n",
       "      <td>-0.296531</td>\n",
       "      <td>0.372608</td>\n",
       "      <td>-0.541009</td>\n",
       "      <td>-0.653288</td>\n",
       "      <td>0.318019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>557</td>\n",
       "      <td>-0.523181</td>\n",
       "      <td>-0.478655</td>\n",
       "      <td>0.176158</td>\n",
       "      <td>-0.245387</td>\n",
       "      <td>1.144202</td>\n",
       "      <td>0.284027</td>\n",
       "      <td>1.830700</td>\n",
       "      <td>0.202389</td>\n",
       "      <td>-0.491186</td>\n",
       "      <td>0.489575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>836</td>\n",
       "      <td>2.244197</td>\n",
       "      <td>1.225454</td>\n",
       "      <td>-0.828965</td>\n",
       "      <td>-0.111927</td>\n",
       "      <td>0.375417</td>\n",
       "      <td>0.444073</td>\n",
       "      <td>-0.835202</td>\n",
       "      <td>-0.458208</td>\n",
       "      <td>0.612965</td>\n",
       "      <td>-0.562706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.394877</td>\n",
       "      <td>-1.394822</td>\n",
       "      <td>0.255025</td>\n",
       "      <td>0.818061</td>\n",
       "      <td>-0.053974</td>\n",
       "      <td>0.193075</td>\n",
       "      <td>-0.785655</td>\n",
       "      <td>0.108597</td>\n",
       "      <td>0.451189</td>\n",
       "      <td>-0.765413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>-0.008923</td>\n",
       "      <td>-0.601086</td>\n",
       "      <td>-0.054966</td>\n",
       "      <td>0.985366</td>\n",
       "      <td>-0.052347</td>\n",
       "      <td>-0.303155</td>\n",
       "      <td>0.076224</td>\n",
       "      <td>-0.498821</td>\n",
       "      <td>-0.466354</td>\n",
       "      <td>-1.514645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>-1.305500</td>\n",
       "      <td>3.159843</td>\n",
       "      <td>-0.985534</td>\n",
       "      <td>-1.357325</td>\n",
       "      <td>-0.480135</td>\n",
       "      <td>0.096085</td>\n",
       "      <td>-1.149118</td>\n",
       "      <td>0.994904</td>\n",
       "      <td>-0.804308</td>\n",
       "      <td>-1.595492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435</td>\n",
       "      <td>0.470365</td>\n",
       "      <td>-1.164993</td>\n",
       "      <td>-0.227289</td>\n",
       "      <td>-1.143914</td>\n",
       "      <td>2.274234</td>\n",
       "      <td>-0.661404</td>\n",
       "      <td>-2.009812</td>\n",
       "      <td>0.882182</td>\n",
       "      <td>-1.717222</td>\n",
       "      <td>0.064218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>-1.194242</td>\n",
       "      <td>-0.014074</td>\n",
       "      <td>0.284175</td>\n",
       "      <td>-1.637931</td>\n",
       "      <td>-0.697795</td>\n",
       "      <td>-0.254765</td>\n",
       "      <td>2.476250</td>\n",
       "      <td>-1.557357</td>\n",
       "      <td>-1.044485</td>\n",
       "      <td>-0.674363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x0        x1        x2        x3        x4        x5        x6  \\\n",
       "29  -3.135568 -0.682559 -0.740026 -1.565277  0.653032 -0.910702 -1.571373   \n",
       "535 -0.220983  1.681607  1.541841 -0.190491  1.520588  0.938335  1.503033   \n",
       "695 -0.106349 -0.442650  1.933125 -0.034856  0.534739 -0.296531  0.372608   \n",
       "557 -0.523181 -0.478655  0.176158 -0.245387  1.144202  0.284027  1.830700   \n",
       "836  2.244197  1.225454 -0.828965 -0.111927  0.375417  0.444073 -0.835202   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "106  0.394877 -1.394822  0.255025  0.818061 -0.053974  0.193075 -0.785655   \n",
       "270 -0.008923 -0.601086 -0.054966  0.985366 -0.052347 -0.303155  0.076224   \n",
       "860 -1.305500  3.159843 -0.985534 -1.357325 -0.480135  0.096085 -1.149118   \n",
       "435  0.470365 -1.164993 -0.227289 -1.143914  2.274234 -0.661404 -2.009812   \n",
       "102 -1.194242 -0.014074  0.284175 -1.637931 -0.697795 -0.254765  2.476250   \n",
       "\n",
       "           x7        x8        x9  \n",
       "29  -0.106283 -0.794989  0.250017  \n",
       "535 -0.538354  0.116053  0.690656  \n",
       "695 -0.541009 -0.653288  0.318019  \n",
       "557  0.202389 -0.491186  0.489575  \n",
       "836 -0.458208  0.612965 -0.562706  \n",
       "..        ...       ...       ...  \n",
       "106  0.108597  0.451189 -0.765413  \n",
       "270 -0.498821 -0.466354 -1.514645  \n",
       "860  0.994904 -0.804308 -1.595492  \n",
       "435  0.882182 -1.717222  0.064218  \n",
       "102 -1.557357 -1.044485 -0.674363  \n",
       "\n",
       "[800 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_score = lambda y_true, y_pred: -mean_squared_error(y_true, y_pred)\n",
    "scoring = 'neg_mean_squared_error'\n",
    "\n",
    "cv = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:12:49]  LGBMRegressor\n",
      "\n",
      "[06:12:49]  FOLD  0:   -1849.9203\n",
      "[06:12:49]  FOLD  1:   -985.8744\n",
      "[06:12:49]  FOLD  2:   -1560.7978\n",
      "[06:12:49]  FOLD  3:   -1821.7524\n",
      "[06:12:49]  FOLD  4:   -1409.5014\n",
      "\n",
      "[06:12:50]  AVERAGE:   -1525.5693 Â± 315.8833\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1294.5736816744054"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMRegressor()\n",
    "\n",
    "_, y_pred = crossval_predict(model, cv, X_train, y_train, X_new=X_test,\n",
    "                             scoring=scoring, verbose=2, n_jobs=None)\n",
    "\n",
    "get_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:12:50] ITER: 1/80      SCORE: -1874.0342 Â± 225.4839      ETA: 19 sec\n",
      "bagging_fraction    0.2\n",
      "feature_fraction    0.2\n",
      "learning_rate       0.2\n",
      "max_depth           4.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:50] ITER: 2/80      SCORE: -2918.6195 Â± 254.5045      ETA: 19 sec\n",
      "bagging_fraction    0.2\n",
      "feature_fraction    0.2\n",
      "learning_rate       0.2\n",
      "max_depth           6.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:51] ITER: 3/80      SCORE: -3442.7426 Â± 229.3320      ETA: 21 sec\n",
      "bagging_fraction    0.2\n",
      "feature_fraction    0.2\n",
      "learning_rate       0.2\n",
      "max_depth           8.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:51] ITER: 4/80      SCORE: -3505.8605 Â± 353.3925      ETA: 21 sec\n",
      "bagging_fraction     0.2\n",
      "feature_fraction     0.2\n",
      "learning_rate        0.2\n",
      "max_depth           10.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:51] ITER: 5/80      SCORE: -3595.3033 Â± 298.1406      ETA: 21 sec\n",
      "bagging_fraction     0.2\n",
      "feature_fraction     0.2\n",
      "learning_rate        0.2\n",
      "max_depth           12.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:52] ITER: 6/80      SCORE: -1280.6089 Â± 238.2378      ETA: 21 sec\n",
      "bagging_fraction    0.2\n",
      "feature_fraction    0.4\n",
      "learning_rate       0.2\n",
      "max_depth           4.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:52] ITER: 7/80      SCORE: -1749.7178 Â± 240.2208      ETA: 21 sec\n",
      "bagging_fraction    0.2\n",
      "feature_fraction    0.4\n",
      "learning_rate       0.2\n",
      "max_depth           6.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:52] ITER: 8/80      SCORE: -1948.7771 Â± 318.8439      ETA: 21 sec\n",
      "bagging_fraction    0.2\n",
      "feature_fraction    0.4\n",
      "learning_rate       0.2\n",
      "max_depth           8.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:53] ITER: 9/80      SCORE: -2051.8146 Â± 254.4649      ETA: 21 sec\n",
      "bagging_fraction     0.2\n",
      "feature_fraction     0.4\n",
      "learning_rate        0.2\n",
      "max_depth           10.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:53] ITER: 10/80      SCORE: -2041.9131 Â± 270.7274      ETA: 21 sec\n",
      "bagging_fraction     0.2\n",
      "feature_fraction     0.4\n",
      "learning_rate        0.2\n",
      "max_depth           12.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:53] ITER: 11/80      SCORE: -1240.4311 Â± 198.7903      ETA: 21 sec\n",
      "bagging_fraction    0.2\n",
      "feature_fraction    0.6\n",
      "learning_rate       0.2\n",
      "max_depth           4.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:54] ITER: 12/80      SCORE: -1507.2518 Â± 196.1622      ETA: 20 sec\n",
      "bagging_fraction    0.2\n",
      "feature_fraction    0.6\n",
      "learning_rate       0.2\n",
      "max_depth           6.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:54] ITER: 13/80      SCORE: -1514.1407 Â± 221.2528      ETA: 20 sec\n",
      "bagging_fraction    0.2\n",
      "feature_fraction    0.6\n",
      "learning_rate       0.2\n",
      "max_depth           8.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:54] ITER: 14/80      SCORE: -1523.0744 Â± 198.5755      ETA: 20 sec\n",
      "bagging_fraction     0.2\n",
      "feature_fraction     0.6\n",
      "learning_rate        0.2\n",
      "max_depth           10.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:55] ITER: 15/80      SCORE: -1544.4474 Â± 218.1813      ETA: 20 sec\n",
      "bagging_fraction     0.2\n",
      "feature_fraction     0.6\n",
      "learning_rate        0.2\n",
      "max_depth           12.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:55] ITER: 16/80      SCORE: -1246.1382 Â± 231.8084      ETA: 20 sec\n",
      "bagging_fraction    0.2\n",
      "feature_fraction    0.8\n",
      "learning_rate       0.2\n",
      "max_depth           4.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:55] ITER: 17/80      SCORE: -1378.3118 Â± 171.0077      ETA: 19 sec\n",
      "bagging_fraction    0.2\n",
      "feature_fraction    0.8\n",
      "learning_rate       0.2\n",
      "max_depth           6.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:56] ITER: 18/80      SCORE: -1385.7514 Â± 188.2552      ETA: 19 sec\n",
      "bagging_fraction    0.2\n",
      "feature_fraction    0.8\n",
      "learning_rate       0.2\n",
      "max_depth           8.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:56] ITER: 19/80      SCORE: -1389.6146 Â± 151.3701      ETA: 19 sec\n",
      "bagging_fraction     0.2\n",
      "feature_fraction     0.8\n",
      "learning_rate        0.2\n",
      "max_depth           10.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:57] ITER: 20/80      SCORE: -1416.3087 Â± 203.8082      ETA: 19 sec\n",
      "bagging_fraction     0.2\n",
      "feature_fraction     0.8\n",
      "learning_rate        0.2\n",
      "max_depth           12.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:57] ITER: 21/80      SCORE: -1874.0342 Â± 225.4839      ETA: 19 sec\n",
      "bagging_fraction    0.4\n",
      "feature_fraction    0.2\n",
      "learning_rate       0.2\n",
      "max_depth           4.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:57] ITER: 22/80      SCORE: -2918.6195 Â± 254.5045      ETA: 18 sec\n",
      "bagging_fraction    0.4\n",
      "feature_fraction    0.2\n",
      "learning_rate       0.2\n",
      "max_depth           6.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:58] ITER: 23/80      SCORE: -3442.7426 Â± 229.3320      ETA: 18 sec\n",
      "bagging_fraction    0.4\n",
      "feature_fraction    0.2\n",
      "learning_rate       0.2\n",
      "max_depth           8.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:58] ITER: 24/80      SCORE: -3505.8605 Â± 353.3925      ETA: 18 sec\n",
      "bagging_fraction     0.4\n",
      "feature_fraction     0.2\n",
      "learning_rate        0.2\n",
      "max_depth           10.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:58] ITER: 25/80      SCORE: -3595.3033 Â± 298.1406      ETA: 18 sec\n",
      "bagging_fraction     0.4\n",
      "feature_fraction     0.2\n",
      "learning_rate        0.2\n",
      "max_depth           12.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:59] ITER: 26/80      SCORE: -1280.6089 Â± 238.2378      ETA: 17 sec\n",
      "bagging_fraction    0.4\n",
      "feature_fraction    0.4\n",
      "learning_rate       0.2\n",
      "max_depth           4.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:59] ITER: 27/80      SCORE: -1749.7178 Â± 240.2208      ETA: 17 sec\n",
      "bagging_fraction    0.4\n",
      "feature_fraction    0.4\n",
      "learning_rate       0.2\n",
      "max_depth           6.0\n",
      "dtype: float64\n",
      "\n",
      "[06:12:59] ITER: 28/80      SCORE: -1948.7771 Â± 318.8439      ETA: 16 sec\n",
      "bagging_fraction    0.4\n",
      "feature_fraction    0.4\n",
      "learning_rate       0.2\n",
      "max_depth           8.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:00] ITER: 29/80      SCORE: -2051.8146 Â± 254.4649      ETA: 16 sec\n",
      "bagging_fraction     0.4\n",
      "feature_fraction     0.4\n",
      "learning_rate        0.2\n",
      "max_depth           10.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:00] ITER: 30/80      SCORE: -2041.9131 Â± 270.7274      ETA: 16 sec\n",
      "bagging_fraction     0.4\n",
      "feature_fraction     0.4\n",
      "learning_rate        0.2\n",
      "max_depth           12.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:00] ITER: 31/80      SCORE: -1240.4311 Â± 198.7903      ETA: 15 sec\n",
      "bagging_fraction    0.4\n",
      "feature_fraction    0.6\n",
      "learning_rate       0.2\n",
      "max_depth           4.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:01] ITER: 32/80      SCORE: -1507.2518 Â± 196.1622      ETA: 15 sec\n",
      "bagging_fraction    0.4\n",
      "feature_fraction    0.6\n",
      "learning_rate       0.2\n",
      "max_depth           6.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:01] ITER: 33/80      SCORE: -1514.1407 Â± 221.2528      ETA: 15 sec\n",
      "bagging_fraction    0.4\n",
      "feature_fraction    0.6\n",
      "learning_rate       0.2\n",
      "max_depth           8.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:01] ITER: 34/80      SCORE: -1523.0744 Â± 198.5755      ETA: 14 sec\n",
      "bagging_fraction     0.4\n",
      "feature_fraction     0.6\n",
      "learning_rate        0.2\n",
      "max_depth           10.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:02] ITER: 35/80      SCORE: -1544.4474 Â± 218.1813      ETA: 14 sec\n",
      "bagging_fraction     0.4\n",
      "feature_fraction     0.6\n",
      "learning_rate        0.2\n",
      "max_depth           12.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:02] ITER: 36/80      SCORE: -1246.1382 Â± 231.8084      ETA: 14 sec\n",
      "bagging_fraction    0.4\n",
      "feature_fraction    0.8\n",
      "learning_rate       0.2\n",
      "max_depth           4.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:02] ITER: 37/80      SCORE: -1378.3118 Â± 171.0077      ETA: 13 sec\n",
      "bagging_fraction    0.4\n",
      "feature_fraction    0.8\n",
      "learning_rate       0.2\n",
      "max_depth           6.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:03] ITER: 38/80      SCORE: -1385.7514 Â± 188.2552      ETA: 13 sec\n",
      "bagging_fraction    0.4\n",
      "feature_fraction    0.8\n",
      "learning_rate       0.2\n",
      "max_depth           8.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:03] ITER: 39/80      SCORE: -1389.6146 Â± 151.3701      ETA: 13 sec\n",
      "bagging_fraction     0.4\n",
      "feature_fraction     0.8\n",
      "learning_rate        0.2\n",
      "max_depth           10.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:04] ITER: 40/80      SCORE: -1416.3087 Â± 203.8082      ETA: 12 sec\n",
      "bagging_fraction     0.4\n",
      "feature_fraction     0.8\n",
      "learning_rate        0.2\n",
      "max_depth           12.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:04] ITER: 41/80      SCORE: -1874.0342 Â± 225.4839      ETA: 12 sec\n",
      "bagging_fraction    0.6\n",
      "feature_fraction    0.2\n",
      "learning_rate       0.2\n",
      "max_depth           4.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:04] ITER: 42/80      SCORE: -2918.6195 Â± 254.5045      ETA: 12 sec\n",
      "bagging_fraction    0.6\n",
      "feature_fraction    0.2\n",
      "learning_rate       0.2\n",
      "max_depth           6.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:05] ITER: 43/80      SCORE: -3442.7426 Â± 229.3320      ETA: 11 sec\n",
      "bagging_fraction    0.6\n",
      "feature_fraction    0.2\n",
      "learning_rate       0.2\n",
      "max_depth           8.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:05] ITER: 44/80      SCORE: -3505.8605 Â± 353.3925      ETA: 11 sec\n",
      "bagging_fraction     0.6\n",
      "feature_fraction     0.2\n",
      "learning_rate        0.2\n",
      "max_depth           10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype: float64\n",
      "\n",
      "[06:13:05] ITER: 45/80      SCORE: -3595.3033 Â± 298.1406      ETA: 11 sec\n",
      "bagging_fraction     0.6\n",
      "feature_fraction     0.2\n",
      "learning_rate        0.2\n",
      "max_depth           12.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:06] ITER: 46/80      SCORE: -1280.6089 Â± 238.2378      ETA: 10 sec\n",
      "bagging_fraction    0.6\n",
      "feature_fraction    0.4\n",
      "learning_rate       0.2\n",
      "max_depth           4.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:06] ITER: 47/80      SCORE: -1749.7178 Â± 240.2208      ETA: 10 sec\n",
      "bagging_fraction    0.6\n",
      "feature_fraction    0.4\n",
      "learning_rate       0.2\n",
      "max_depth           6.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:06] ITER: 48/80      SCORE: -1948.7771 Â± 318.8439      ETA: 10 sec\n",
      "bagging_fraction    0.6\n",
      "feature_fraction    0.4\n",
      "learning_rate       0.2\n",
      "max_depth           8.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:07] ITER: 49/80      SCORE: -2051.8146 Â± 254.4649      ETA: 9 sec\n",
      "bagging_fraction     0.6\n",
      "feature_fraction     0.4\n",
      "learning_rate        0.2\n",
      "max_depth           10.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:07] ITER: 50/80      SCORE: -2041.9131 Â± 270.7274      ETA: 9 sec\n",
      "bagging_fraction     0.6\n",
      "feature_fraction     0.4\n",
      "learning_rate        0.2\n",
      "max_depth           12.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:07] ITER: 51/80      SCORE: -1240.4311 Â± 198.7903      ETA: 9 sec\n",
      "bagging_fraction    0.6\n",
      "feature_fraction    0.6\n",
      "learning_rate       0.2\n",
      "max_depth           4.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:07] ITER: 52/80      SCORE: -1507.2518 Â± 196.1622      ETA: 8 sec\n",
      "bagging_fraction    0.6\n",
      "feature_fraction    0.6\n",
      "learning_rate       0.2\n",
      "max_depth           6.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:08] ITER: 53/80      SCORE: -1514.1407 Â± 221.2528      ETA: 8 sec\n",
      "bagging_fraction    0.6\n",
      "feature_fraction    0.6\n",
      "learning_rate       0.2\n",
      "max_depth           8.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:08] ITER: 54/80      SCORE: -1523.0744 Â± 198.5755      ETA: 8 sec\n",
      "bagging_fraction     0.6\n",
      "feature_fraction     0.6\n",
      "learning_rate        0.2\n",
      "max_depth           10.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:09] ITER: 55/80      SCORE: -1544.4474 Â± 218.1813      ETA: 8 sec\n",
      "bagging_fraction     0.6\n",
      "feature_fraction     0.6\n",
      "learning_rate        0.2\n",
      "max_depth           12.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:09] ITER: 56/80      SCORE: -1246.1382 Â± 231.8084      ETA: 7 sec\n",
      "bagging_fraction    0.6\n",
      "feature_fraction    0.8\n",
      "learning_rate       0.2\n",
      "max_depth           4.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:09] ITER: 57/80      SCORE: -1378.3118 Â± 171.0077      ETA: 7 sec\n",
      "bagging_fraction    0.6\n",
      "feature_fraction    0.8\n",
      "learning_rate       0.2\n",
      "max_depth           6.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:10] ITER: 58/80      SCORE: -1385.7514 Â± 188.2552      ETA: 7 sec\n",
      "bagging_fraction    0.6\n",
      "feature_fraction    0.8\n",
      "learning_rate       0.2\n",
      "max_depth           8.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:10] ITER: 59/80      SCORE: -1389.6146 Â± 151.3701      ETA: 6 sec\n",
      "bagging_fraction     0.6\n",
      "feature_fraction     0.8\n",
      "learning_rate        0.2\n",
      "max_depth           10.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:11] ITER: 60/80      SCORE: -1416.3087 Â± 203.8082      ETA: 6 sec\n",
      "bagging_fraction     0.6\n",
      "feature_fraction     0.8\n",
      "learning_rate        0.2\n",
      "max_depth           12.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:11] ITER: 61/80      SCORE: -1874.0342 Â± 225.4839      ETA: 6 sec\n",
      "bagging_fraction    0.8\n",
      "feature_fraction    0.2\n",
      "learning_rate       0.2\n",
      "max_depth           4.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:12] ITER: 62/80      SCORE: -2918.6195 Â± 254.5045      ETA: 5 sec\n",
      "bagging_fraction    0.8\n",
      "feature_fraction    0.2\n",
      "learning_rate       0.2\n",
      "max_depth           6.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:12] ITER: 63/80      SCORE: -3442.7426 Â± 229.3320      ETA: 5 sec\n",
      "bagging_fraction    0.8\n",
      "feature_fraction    0.2\n",
      "learning_rate       0.2\n",
      "max_depth           8.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:12] ITER: 64/80      SCORE: -3505.8605 Â± 353.3925      ETA: 5 sec\n",
      "bagging_fraction     0.8\n",
      "feature_fraction     0.2\n",
      "learning_rate        0.2\n",
      "max_depth           10.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:13] ITER: 65/80      SCORE: -3595.3033 Â± 298.1406      ETA: 4 sec\n",
      "bagging_fraction     0.8\n",
      "feature_fraction     0.2\n",
      "learning_rate        0.2\n",
      "max_depth           12.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:13] ITER: 66/80      SCORE: -1280.6089 Â± 238.2378      ETA: 4 sec\n",
      "bagging_fraction    0.8\n",
      "feature_fraction    0.4\n",
      "learning_rate       0.2\n",
      "max_depth           4.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:13] ITER: 67/80      SCORE: -1749.7178 Â± 240.2208      ETA: 4 sec\n",
      "bagging_fraction    0.8\n",
      "feature_fraction    0.4\n",
      "learning_rate       0.2\n",
      "max_depth           6.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:14] ITER: 68/80      SCORE: -1948.7771 Â± 318.8439      ETA: 3 sec\n",
      "bagging_fraction    0.8\n",
      "feature_fraction    0.4\n",
      "learning_rate       0.2\n",
      "max_depth           8.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:14] ITER: 69/80      SCORE: -2051.8146 Â± 254.4649      ETA: 3 sec\n",
      "bagging_fraction     0.8\n",
      "feature_fraction     0.4\n",
      "learning_rate        0.2\n",
      "max_depth           10.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:15] ITER: 70/80      SCORE: -2041.9131 Â± 270.7274      ETA: 3 sec\n",
      "bagging_fraction     0.8\n",
      "feature_fraction     0.4\n",
      "learning_rate        0.2\n",
      "max_depth           12.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:15] ITER: 71/80      SCORE: -1240.4311 Â± 198.7903      ETA: 2 sec\n",
      "bagging_fraction    0.8\n",
      "feature_fraction    0.6\n",
      "learning_rate       0.2\n",
      "max_depth           4.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:15] ITER: 72/80      SCORE: -1507.2518 Â± 196.1622      ETA: 2 sec\n",
      "bagging_fraction    0.8\n",
      "feature_fraction    0.6\n",
      "learning_rate       0.2\n",
      "max_depth           6.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:16] ITER: 73/80      SCORE: -1514.1407 Â± 221.2528      ETA: 2 sec\n",
      "bagging_fraction    0.8\n",
      "feature_fraction    0.6\n",
      "learning_rate       0.2\n",
      "max_depth           8.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:16] ITER: 74/80      SCORE: -1523.0744 Â± 198.5755      ETA: 2 sec\n",
      "bagging_fraction     0.8\n",
      "feature_fraction     0.6\n",
      "learning_rate        0.2\n",
      "max_depth           10.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:17] ITER: 75/80      SCORE: -1544.4474 Â± 218.1813      ETA: 1 sec\n",
      "bagging_fraction     0.8\n",
      "feature_fraction     0.6\n",
      "learning_rate        0.2\n",
      "max_depth           12.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:17] ITER: 76/80      SCORE: -1246.1382 Â± 231.8084      ETA: 1 sec\n",
      "bagging_fraction    0.8\n",
      "feature_fraction    0.8\n",
      "learning_rate       0.2\n",
      "max_depth           4.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:17] ITER: 77/80      SCORE: -1378.3118 Â± 171.0077      ETA: 1 sec\n",
      "bagging_fraction    0.8\n",
      "feature_fraction    0.8\n",
      "learning_rate       0.2\n",
      "max_depth           6.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:18] ITER: 78/80      SCORE: -1385.7514 Â± 188.2552      ETA: 669 ms\n",
      "bagging_fraction    0.8\n",
      "feature_fraction    0.8\n",
      "learning_rate       0.2\n",
      "max_depth           8.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:18] ITER: 79/80      SCORE: -1389.6146 Â± 151.3701      ETA: 336 ms\n",
      "bagging_fraction     0.8\n",
      "feature_fraction     0.8\n",
      "learning_rate        0.2\n",
      "max_depth           10.0\n",
      "dtype: float64\n",
      "\n",
      "[06:13:19] ITER: 80/80      SCORE: -1416.3087 Â± 203.8082      ETA: 0 ms\n",
      "bagging_fraction     0.8\n",
      "feature_fraction     0.8\n",
      "learning_rate        0.2\n",
      "max_depth           12.0\n",
      "dtype: float64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, debug=False,\n",
       "             estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None,\n",
       "                                     colsample_bytree=1.0,\n",
       "                                     importance_type='split', learning_rate=0.1,\n",
       "                                     max_depth=-1, min_child_samples=20,\n",
       "                                     min_child_weight=0.001, min_split_gain=0.0,\n",
       "                                     n_estimators=100, n_jobs=-1, num_leaves=31,\n",
       "                                     objective=None, random_state=None,\n",
       "                                     reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "                                     subsample=1.0, subsample_for_bin=200000,\n",
       "                                     subsample_freq=0),\n",
       "             max_iter=80, max_time=None, n_digits=4, n_jobs=None,\n",
       "             param_space={'bagging_fraction': (0.2, 0.8, 0.2),\n",
       "                          'feature_fraction': (0.2, 0.8, 0.2),\n",
       "                          'learning_rate': 0.2, 'max_depth': (4, 12, 2)},\n",
       "             plot=False, scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMRegressor()\n",
    "\n",
    "# https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "param_space = {\n",
    "    'learning_rate': 0.2,\n",
    "    'max_depth': (4, 12, 2),\n",
    "    \n",
    "    'bagging_fraction': (0.2, 0.8, 0.2),\n",
    "    'feature_fraction': (0.2, 0.8, 0.2),\n",
    "}\n",
    "\n",
    "optimizer = GridSearchCV(model, cv, scoring, param_space=param_space, verbose=2)\n",
    "optimizer.fit(X_train, y_train)\n",
    "\n",
    "#optimizer.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:13:19]  LGBMRegressor\n",
      "\n",
      "[06:13:19]  FOLD  0:   -1600.2658\n",
      "[06:13:19]  FOLD  1:   -1104.0291\n",
      "[06:13:19]  FOLD  2:   -1228.1365\n",
      "[06:13:19]  FOLD  3:   -1251.1818\n",
      "[06:13:19]  FOLD  4:   -1018.5424\n",
      "\n",
      "[06:13:20]  AVERAGE:   -1240.4311 Â± 198.7903\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-854.3026163822387"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = optimizer.best_estimator_\n",
    "\n",
    "_, y_pred = crossval_predict(model, cv, X_train, y_train, X_new=X_test,\n",
    "                             scoring=scoring, verbose=2, n_jobs=None)\n",
    "\n",
    "get_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:13:40] ITER: 1/30      SCORE: -1510.0740 Â± 228.2347      ETA: 10 sec\n",
      "[06:13:41] ITER: 2/30      SCORE: -1823.8668 Â± 356.8841      ETA: 18 sec\n",
      "[06:13:42] ITER: 3/30      SCORE: -1809.7237 Â± 336.2711      ETA: 15 sec\n",
      "[06:13:42] ITER: 4/30      SCORE: -1508.8063 Â± 257.6029      ETA: 14 sec\n",
      "[06:13:43] ITER: 5/30      SCORE: -7889.4019 Â± 729.3220      ETA: 12 sec\n",
      "[06:13:44] ITER: 6/30      SCORE: -1301.2092 Â± 232.7649      ETA: 12 sec\n",
      "[06:13:45] ITER: 7/30      SCORE: -1468.2790 Â± 290.5045      ETA: 13 sec\n",
      "[06:13:46] ITER: 8/30      SCORE: -1427.0582 Â± 256.7935      ETA: 13 sec\n",
      "[06:13:46] ITER: 9/30      SCORE: -1823.8668 Â± 356.8841      ETA: 12 sec\n",
      "[06:13:47] ITER: 10/30      SCORE: -1427.0582 Â± 256.7935      ETA: 11 sec\n",
      "[06:13:47] ITER: 11/30      SCORE: -1366.7639 Â± 272.2196      ETA: 10 sec\n",
      "[06:13:48] ITER: 12/30      SCORE: -1358.4104 Â± 222.0262      ETA: 10 sec\n",
      "[06:13:49] ITER: 13/30      SCORE: -8131.6719 Â± 735.3454      ETA: 9 sec\n",
      "[06:13:49] ITER: 14/30      SCORE: -3442.7375 Â± 378.1174      ETA: 8 sec\n",
      "[06:13:50] ITER: 15/30      SCORE: -1366.7639 Â± 272.2196      ETA: 8 sec\n",
      "[06:13:51] ITER: 16/30      SCORE: -1308.0683 Â± 229.8175      ETA: 7 sec\n",
      "[06:13:52] ITER: 17/30      SCORE: -1495.8676 Â± 239.5963      ETA: 7 sec\n",
      "[06:13:54] ITER: 18/30      SCORE: -2300.6192 Â± 380.0358      ETA: 7 sec\n",
      "[06:13:54] ITER: 19/30      SCORE: -1360.0800 Â± 272.6787      ETA: 6 sec\n",
      "[06:13:55] ITER: 20/30      SCORE: -7425.4598 Â± 755.7063      ETA: 6 sec\n",
      "[06:13:55] ITER: 21/30      SCORE: -1390.5810 Â± 264.9797      ETA: 5 sec\n",
      "[06:13:56] ITER: 22/30      SCORE: -7425.4598 Â± 755.7063      ETA: 4 sec\n",
      "[06:13:56] ITER: 23/30      SCORE: -1483.6737 Â± 348.3294      ETA: 4 sec\n",
      "[06:13:57] ITER: 24/30      SCORE: -1375.3687 Â± 240.1025      ETA: 3 sec\n",
      "[06:13:58] ITER: 25/30      SCORE: -1301.2092 Â± 232.7649      ETA: 2 sec\n",
      "[06:13:58] ITER: 26/30      SCORE: -1906.1676 Â± 297.2228      ETA: 2 sec\n",
      "[06:13:59] ITER: 27/30      SCORE: -1388.3638 Â± 258.7520      ETA: 1 sec\n",
      "[06:13:59] ITER: 28/30      SCORE: -1366.7639 Â± 272.2196      ETA: 1 sec\n",
      "[06:14:00] ITER: 29/30      SCORE: -3822.8890 Â± 352.6519      ETA: 549 ms\n",
      "[06:14:01] ITER: 30/30      SCORE: -1906.1676 Â± 297.2228      ETA: 0 ms\n",
      "Iterations limit exceed!\n"
     ]
    }
   ],
   "source": [
    "model = LGBMRegressor()\n",
    "\n",
    "# https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "param_space = {\n",
    "    'max_depth': (3, 12, 1),\n",
    "    'num_leaves': {15, 31, 63, 127, 255, 511, 1023, 2047, 4095},\n",
    "\n",
    "    'bagging_fraction': (0.1, 0.9, 0.05),\n",
    "    'feature_fraction': (0.1, 0.9, 0.05),\n",
    "}\n",
    "\n",
    "optimizer = RandomSearchCV(model, cv, scoring, param_space=param_space, max_iter=30)\n",
    "optimizer.fit(X_train, y_train)\n",
    "\n",
    "#optimizer.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:14:02]  LGBMRegressor\n",
      "\n",
      "[06:14:02]  FOLD  0:   -1560.0592\n",
      "[06:14:03]  FOLD  1:   -909.4342\n",
      "[06:14:03]  FOLD  2:   -1341.3244\n",
      "[06:14:03]  FOLD  3:   -1496.7623\n",
      "[06:14:03]  FOLD  4:   -1198.4657\n",
      "\n",
      "[06:14:03]  AVERAGE:   -1301.2092 Â± 232.7649\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1081.4048269434836"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = optimizer.best_estimator_\n",
    "\n",
    "_, y_pred = crossval_predict(model, cv, X_train, y_train, X_new=X_test,\n",
    "                             scoring=scoring, verbose=2, n_jobs=None)\n",
    "\n",
    "get_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:14:37] ITER: 1/30      SCORE: -1510.0740 Â± 228.2347      ETA: 11 sec\n",
      "[06:14:38] ITER: 2/30      SCORE: -1823.8668 Â± 356.8841      ETA: 18 sec\n",
      "[06:14:38] ITER: 3/30      SCORE: -1809.7237 Â± 336.2711      ETA: 14 sec\n",
      "[06:14:39] ITER: 4/30      SCORE: -1508.8063 Â± 257.6029      ETA: 12 sec\n",
      "[06:14:39] ITER: 5/30      SCORE: -7889.4019 Â± 729.3220      ETA: 10 sec\n",
      "[06:14:40] ITER: 6/30      SCORE: -1301.2092 Â± 232.7649      ETA: 10 sec\n",
      "[06:14:41] ITER: 7/30      SCORE: -1468.2790 Â± 290.5045      ETA: 11 sec\n",
      "[06:14:42] ITER: 8/30      SCORE: -1427.0582 Â± 256.7935      ETA: 11 sec\n",
      "[06:14:42] ITER: 9/30      SCORE: -1823.8668 Â± 356.8841      ETA: 10 sec\n",
      "[06:14:43] ITER: 10/30      SCORE: -1427.0582 Â± 256.7935      ETA: 9 sec\n",
      "[06:14:43] ITER: 11/30      SCORE: -1300.4823 Â± 236.3293      ETA: 8 sec\n",
      "[06:14:44] ITER: 12/30      SCORE: -1311.3966 Â± 247.2201      ETA: 8 sec\n",
      "[06:14:44] ITER: 13/30      SCORE: -1311.3966 Â± 247.2201      ETA: 7 sec\n",
      "[06:14:44] ITER: 14/30      SCORE: -1295.0819 Â± 248.8429      ETA: 6 sec\n",
      "[06:14:45] ITER: 15/30      SCORE: -1291.6050 Â± 255.0114      ETA: 6 sec\n",
      "[06:14:45] ITER: 16/30      SCORE: -1291.6050 Â± 255.0114      ETA: 5 sec\n",
      "[06:14:46] ITER: 17/30      SCORE: -1291.6050 Â± 255.0114      ETA: 5 sec\n",
      "[06:14:46] ITER: 18/30      SCORE: -1302.9820 Â± 229.6728      ETA: 4 sec\n",
      "[06:14:46] ITER: 19/30      SCORE: -1589.3104 Â± 275.1220      ETA: 4 sec\n",
      "[06:14:47] ITER: 20/30      SCORE: -1362.6706 Â± 230.0949      ETA: 3 sec\n",
      "[06:14:47] ITER: 21/30      SCORE: -1302.9820 Â± 229.6728      ETA: 3 sec\n",
      "[06:14:48] ITER: 22/30      SCORE: -1291.6050 Â± 255.0114      ETA: 2 sec\n",
      "[06:14:48] ITER: 23/30      SCORE: -1291.6050 Â± 255.0114      ETA: 2 sec\n",
      "[06:14:49] ITER: 24/30      SCORE: -1300.4823 Â± 236.3293      ETA: 2 sec\n",
      "[06:14:49] ITER: 25/30      SCORE: -1302.9820 Â± 229.6728      ETA: 1 sec\n",
      "[06:14:49] ITER: 26/30      SCORE: -1251.7069 Â± 199.7595      ETA: 1 sec\n",
      "[06:14:50] ITER: 27/30      SCORE: -1375.3687 Â± 240.1025      ETA: 1 sec\n",
      "[06:14:50] ITER: 28/30      SCORE: -1251.7069 Â± 199.7595      ETA: 692 ms\n",
      "[06:14:51] ITER: 29/30      SCORE: -1362.6706 Â± 230.0949      ETA: 345 ms\n",
      "[06:14:52] ITER: 30/30      SCORE: -1375.3687 Â± 240.1025      ETA: 0 ms\n",
      "Iterations limit exceed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OptunaCV(cv=5, debug=False,\n",
       "         estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None,\n",
       "                                 colsample_bytree=1.0, importance_type='split',\n",
       "                                 learning_rate=0.1, max_depth=-1,\n",
       "                                 min_child_samples=20, min_child_weight=0.001,\n",
       "                                 min_split_gain=0.0, n_estimators=100,\n",
       "                                 n_jobs=-1, num_leaves=31, objective=None,\n",
       "                                 random_state=None, reg_alpha=0.0,\n",
       "                                 reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "                                 subsample_for_bin=200000, subsample_freq=0),\n",
       "         max_iter=30, max_time=None, n_digits=4, n_jobs=None,\n",
       "         param_space={'bagging_fraction': (0.1, 0.9, 0.05),\n",
       "                      'feature_fraction': (0.1, 0.9, 0.05),\n",
       "                      'max_depth': (3, 12, 1),\n",
       "                      'num_leaves': {15, 31, 63, 127, 255, 511, 1023, 2047,\n",
       "                                     4095}},\n",
       "         plot=False, scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMRegressor()\n",
    "\n",
    "# https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "param_space = {\n",
    "    'max_depth': (3, 12, 1),\n",
    "    'num_leaves': {15, 31, 63, 127, 255, 511, 1023, 2047, 4095},\n",
    "\n",
    "    'bagging_fraction': (0.1, 0.9, 0.05),\n",
    "    'feature_fraction': (0.1, 0.9, 0.05),\n",
    "}\n",
    "\n",
    "optimizer = OptunaCV(model, cv, scoring, param_space=param_space, max_iter=30)\n",
    "optimizer.fit(X_train, y_train)\n",
    "\n",
    "#optimizer.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:14:56]  LGBMRegressor\n",
      "\n",
      "[06:14:56]  FOLD  0:   -1501.5237\n",
      "[06:14:56]  FOLD  1:   -939.1182\n",
      "[06:14:56]  FOLD  2:   -1344.6867\n",
      "[06:14:56]  FOLD  3:   -1359.6837\n",
      "[06:14:56]  FOLD  4:   -1113.5222\n",
      "\n",
      "[06:14:57]  AVERAGE:   -1251.7069 Â± 199.7595\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1043.4045900900946"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = optimizer.best_estimator_\n",
    "\n",
    "_, y_pred = crossval_predict(model, cv, X_train, y_train, X_new=X_test,\n",
    "                             scoring=scoring, verbose=2, n_jobs=None)\n",
    "\n",
    "get_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
