{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# ML Toolkit\n",
    "from robusta.preprocessing import *\n",
    "from robusta.optimizer import *\n",
    "from robusta.pipeline import *\n",
    "from robusta.crossval import *\n",
    "from sklearn.metrics import *\n",
    "\n",
    "# Model\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=666)\n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "\n",
    "X.rename(columns=lambda x: 'x{}'.format(x), inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>-3.135568</td>\n",
       "      <td>-0.682559</td>\n",
       "      <td>-0.740026</td>\n",
       "      <td>-1.565277</td>\n",
       "      <td>0.653032</td>\n",
       "      <td>-0.910702</td>\n",
       "      <td>-1.571373</td>\n",
       "      <td>-0.106283</td>\n",
       "      <td>-0.794989</td>\n",
       "      <td>0.250017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>535</td>\n",
       "      <td>-0.220983</td>\n",
       "      <td>1.681607</td>\n",
       "      <td>1.541841</td>\n",
       "      <td>-0.190491</td>\n",
       "      <td>1.520588</td>\n",
       "      <td>0.938335</td>\n",
       "      <td>1.503033</td>\n",
       "      <td>-0.538354</td>\n",
       "      <td>0.116053</td>\n",
       "      <td>0.690656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>695</td>\n",
       "      <td>-0.106349</td>\n",
       "      <td>-0.442650</td>\n",
       "      <td>1.933125</td>\n",
       "      <td>-0.034856</td>\n",
       "      <td>0.534739</td>\n",
       "      <td>-0.296531</td>\n",
       "      <td>0.372608</td>\n",
       "      <td>-0.541009</td>\n",
       "      <td>-0.653288</td>\n",
       "      <td>0.318019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>557</td>\n",
       "      <td>-0.523181</td>\n",
       "      <td>-0.478655</td>\n",
       "      <td>0.176158</td>\n",
       "      <td>-0.245387</td>\n",
       "      <td>1.144202</td>\n",
       "      <td>0.284027</td>\n",
       "      <td>1.830700</td>\n",
       "      <td>0.202389</td>\n",
       "      <td>-0.491186</td>\n",
       "      <td>0.489575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>836</td>\n",
       "      <td>2.244197</td>\n",
       "      <td>1.225454</td>\n",
       "      <td>-0.828965</td>\n",
       "      <td>-0.111927</td>\n",
       "      <td>0.375417</td>\n",
       "      <td>0.444073</td>\n",
       "      <td>-0.835202</td>\n",
       "      <td>-0.458208</td>\n",
       "      <td>0.612965</td>\n",
       "      <td>-0.562706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.394877</td>\n",
       "      <td>-1.394822</td>\n",
       "      <td>0.255025</td>\n",
       "      <td>0.818061</td>\n",
       "      <td>-0.053974</td>\n",
       "      <td>0.193075</td>\n",
       "      <td>-0.785655</td>\n",
       "      <td>0.108597</td>\n",
       "      <td>0.451189</td>\n",
       "      <td>-0.765413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>-0.008923</td>\n",
       "      <td>-0.601086</td>\n",
       "      <td>-0.054966</td>\n",
       "      <td>0.985366</td>\n",
       "      <td>-0.052347</td>\n",
       "      <td>-0.303155</td>\n",
       "      <td>0.076224</td>\n",
       "      <td>-0.498821</td>\n",
       "      <td>-0.466354</td>\n",
       "      <td>-1.514645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>-1.305500</td>\n",
       "      <td>3.159843</td>\n",
       "      <td>-0.985534</td>\n",
       "      <td>-1.357325</td>\n",
       "      <td>-0.480135</td>\n",
       "      <td>0.096085</td>\n",
       "      <td>-1.149118</td>\n",
       "      <td>0.994904</td>\n",
       "      <td>-0.804308</td>\n",
       "      <td>-1.595492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435</td>\n",
       "      <td>0.470365</td>\n",
       "      <td>-1.164993</td>\n",
       "      <td>-0.227289</td>\n",
       "      <td>-1.143914</td>\n",
       "      <td>2.274234</td>\n",
       "      <td>-0.661404</td>\n",
       "      <td>-2.009812</td>\n",
       "      <td>0.882182</td>\n",
       "      <td>-1.717222</td>\n",
       "      <td>0.064218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>-1.194242</td>\n",
       "      <td>-0.014074</td>\n",
       "      <td>0.284175</td>\n",
       "      <td>-1.637931</td>\n",
       "      <td>-0.697795</td>\n",
       "      <td>-0.254765</td>\n",
       "      <td>2.476250</td>\n",
       "      <td>-1.557357</td>\n",
       "      <td>-1.044485</td>\n",
       "      <td>-0.674363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x0        x1        x2        x3        x4        x5        x6  \\\n",
       "29  -3.135568 -0.682559 -0.740026 -1.565277  0.653032 -0.910702 -1.571373   \n",
       "535 -0.220983  1.681607  1.541841 -0.190491  1.520588  0.938335  1.503033   \n",
       "695 -0.106349 -0.442650  1.933125 -0.034856  0.534739 -0.296531  0.372608   \n",
       "557 -0.523181 -0.478655  0.176158 -0.245387  1.144202  0.284027  1.830700   \n",
       "836  2.244197  1.225454 -0.828965 -0.111927  0.375417  0.444073 -0.835202   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "106  0.394877 -1.394822  0.255025  0.818061 -0.053974  0.193075 -0.785655   \n",
       "270 -0.008923 -0.601086 -0.054966  0.985366 -0.052347 -0.303155  0.076224   \n",
       "860 -1.305500  3.159843 -0.985534 -1.357325 -0.480135  0.096085 -1.149118   \n",
       "435  0.470365 -1.164993 -0.227289 -1.143914  2.274234 -0.661404 -2.009812   \n",
       "102 -1.194242 -0.014074  0.284175 -1.637931 -0.697795 -0.254765  2.476250   \n",
       "\n",
       "           x7        x8        x9  \n",
       "29  -0.106283 -0.794989  0.250017  \n",
       "535 -0.538354  0.116053  0.690656  \n",
       "695 -0.541009 -0.653288  0.318019  \n",
       "557  0.202389 -0.491186  0.489575  \n",
       "836 -0.458208  0.612965 -0.562706  \n",
       "..        ...       ...       ...  \n",
       "106  0.108597  0.451189 -0.765413  \n",
       "270 -0.498821 -0.466354 -1.514645  \n",
       "860  0.994904 -0.804308 -1.595492  \n",
       "435  0.882182 -1.717222  0.064218  \n",
       "102 -1.557357 -1.044485 -0.674363  \n",
       "\n",
       "[800 rows x 10 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_score = lambda y_true, y_pred: -mean_squared_error(y_true, y_pred)\n",
    "scoring = 'neg_mean_squared_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:32:59]  LGBMRegressor\n",
      "\n",
      "[05:32:59]  FOLD  0:   -1849.9203\n",
      "[05:32:59]  FOLD  1:   -985.8744\n",
      "[05:32:59]  FOLD  2:   -1560.7978\n",
      "[05:32:59]  FOLD  3:   -1821.7524\n",
      "[05:32:59]  FOLD  4:   -1409.5014\n",
      "\n",
      "[05:33:00]  AVERAGE:   -1525.5693 Â± 315.8833\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1294.5736816744054"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, y_pred = crossval_predict(model, cv, X_train, y_train, X_new=X_test,\n",
    "                             scoring=scoring, verbose=2, n_jobs=None)\n",
    "\n",
    "get_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:33:09] ITER: 1/50      SCORE: -1510.0740 Â± 228.2347      ETA: 16 sec\n",
      "[05:33:11] ITER: 2/50      SCORE: -1823.8668 Â± 356.8841      ETA: 34 sec\n",
      "[05:33:11] ITER: 3/50      SCORE: -1809.7237 Â± 336.2711      ETA: 27 sec\n",
      "[05:33:12] ITER: 4/50      SCORE: -1508.8063 Â± 257.6029      ETA: 24 sec\n",
      "[05:33:12] ITER: 5/50      SCORE: -7889.4019 Â± 729.3220      ETA: 21 sec\n",
      "[05:33:13] ITER: 6/50      SCORE: -1301.2092 Â± 232.7649      ETA: 20 sec\n",
      "[05:33:14] ITER: 7/50      SCORE: -1468.2790 Â± 290.5045      ETA: 22 sec\n",
      "[05:33:15] ITER: 8/50      SCORE: -1427.0582 Â± 256.7935      ETA: 24 sec\n",
      "[05:33:15] ITER: 9/50      SCORE: -1823.8668 Â± 356.8841      ETA: 22 sec\n",
      "[05:33:16] ITER: 10/50      SCORE: -1427.0582 Â± 256.7935      ETA: 21 sec\n",
      "[05:33:16] ITER: 11/50      SCORE: -1366.7639 Â± 272.2196      ETA: 19 sec\n",
      "[05:33:17] ITER: 12/50      SCORE: -1358.4104 Â± 222.0262      ETA: 19 sec\n",
      "[05:33:18] ITER: 13/50      SCORE: -8131.6719 Â± 735.3454      ETA: 19 sec\n"
     ]
    }
   ],
   "source": [
    "model = LGBMRegressor()\n",
    "\n",
    "# https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "param_space = {\n",
    "    'max_depth': (3, 12, 1),\n",
    "    'num_leaves': {15, 31, 63, 127, 255, 511, 1023, 2047, 4095},\n",
    "\n",
    "    'bagging_fraction': (0.1, 0.9, 0.05),\n",
    "    'feature_fraction': (0.1, 0.9, 0.05),\n",
    "}\n",
    "\n",
    "optimizer = RandomSearchCV(model, cv, scoring, param_space=param_space, max_iter=50)\n",
    "optimizer.fit(X_train, y_train)\n",
    "\n",
    "model = optimizer.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, y_pred = crossval_predict(model, cv, X_train, y_train, X_new=X_test,\n",
    "                             scoring=scoring, verbose=2, n_jobs=None)\n",
    "\n",
    "get_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:31:24] ITER: 1/20      SCORE: -1510.0740 Â± 228.2347      ETA: 6 sec\n",
      "[05:31:25] ITER: 2/20      SCORE: -1823.8668 Â± 356.8841      ETA: 11 sec\n",
      "[05:31:25] ITER: 3/20      SCORE: -1809.7237 Â± 336.2711      ETA: 9 sec\n",
      "[05:31:26] ITER: 4/20      SCORE: -1508.8063 Â± 257.6029      ETA: 7 sec\n",
      "[05:31:26] ITER: 5/20      SCORE: -7889.4019 Â± 729.3220      ETA: 6 sec\n",
      "[05:31:27] ITER: 6/20      SCORE: -1301.2092 Â± 232.7649      ETA: 6 sec\n",
      "[05:31:28] ITER: 7/20      SCORE: -1468.2790 Â± 290.5045      ETA: 6 sec\n",
      "[05:31:29] ITER: 8/20      SCORE: -1427.0582 Â± 256.7935      ETA: 6 sec\n",
      "[05:31:30] ITER: 9/20      SCORE: -1823.8668 Â± 356.8841      ETA: 5 sec\n",
      "[05:31:30] ITER: 10/20      SCORE: -1427.0582 Â± 256.7935      ETA: 5 sec\n",
      "[05:31:31] ITER: 11/20      SCORE: -1300.4823 Â± 236.3293      ETA: 4 sec\n",
      "[05:31:31] ITER: 12/20      SCORE: -1311.3966 Â± 247.2201      ETA: 3 sec\n",
      "[05:31:32] ITER: 13/20      SCORE: -1311.3966 Â± 247.2201      ETA: 3 sec\n",
      "[05:31:32] ITER: 14/20      SCORE: -1295.0819 Â± 248.8429      ETA: 2 sec\n",
      "[05:31:33] ITER: 15/20      SCORE: -1291.6050 Â± 255.0114      ETA: 2 sec\n",
      "[05:31:33] ITER: 16/20      SCORE: -1291.6050 Â± 255.0114      ETA: 1 sec\n",
      "[05:31:34] ITER: 17/20      SCORE: -1291.6050 Â± 255.0114      ETA: 1 sec\n",
      "[05:31:34] ITER: 18/20      SCORE: -1302.9820 Â± 229.6728      ETA: 824 ms\n",
      "[05:31:34] ITER: 19/20      SCORE: -1589.3104 Â± 275.1220      ETA: 403 ms\n",
      "[05:31:35] ITER: 20/20      SCORE: -1362.6706 Â± 230.0949      ETA: 0 ms\n",
      "Iterations limit exceed!\n"
     ]
    }
   ],
   "source": [
    "model = LGBMRegressor()\n",
    "\n",
    "# https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "param_space = {\n",
    "    'max_depth': (3, 12, 1),\n",
    "    'num_leaves': {15, 31, 63, 127, 255, 511, 1023, 2047, 4095},\n",
    "\n",
    "    'bagging_fraction': (0.1, 0.9, 0.05),\n",
    "    'feature_fraction': (0.1, 0.9, 0.05),\n",
    "}\n",
    "\n",
    "optimizer = OptunaCV(model, cv, scoring, param_space=param_space, max_iter=50)\n",
    "optimizer.fit(X_train, y_train)\n",
    "\n",
    "model = optimizer.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:31:39]  LGBMRegressor\n",
      "\n",
      "[05:31:39]  FOLD  0:   -1512.9140\n",
      "[05:31:39]  FOLD  1:   -837.6900\n",
      "[05:31:39]  FOLD  2:   -1420.9950\n",
      "[05:31:39]  FOLD  3:   -1498.2436\n",
      "[05:31:39]  FOLD  4:   -1188.1824\n",
      "\n",
      "[05:31:39]  AVERAGE:   -1291.6050 Â± 255.0114\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1027.4699800600881"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, y_pred = crossval_predict(model, cv, X_train, y_train, X_new=X_test,\n",
    "                             scoring=scoring, verbose=2, n_jobs=None)\n",
    "\n",
    "get_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
